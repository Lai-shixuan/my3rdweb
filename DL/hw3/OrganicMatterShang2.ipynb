{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Includes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "_exp_name = \"sample\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T11:05:38.613113600Z",
     "start_time": "2023-11-17T11:05:38.594579500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Import necessary packages.\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import datetime\n",
    "from PIL import Image\n",
    "# \"ConcatDataset\" and \"Subset\" are possibly useful when doing semi-supervised learning.\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset\n",
    "from torchvision.datasets import DatasetFolder, VisionDataset\n",
    "import pandas as pd\n",
    "\n",
    "# This is for the progress bar.\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import csv\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from torcheval.metrics import R2Score\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "papermill": {
     "duration": 1.654263,
     "end_time": "2022-02-23T10:03:07.947242",
     "exception": false,
     "start_time": "2022-02-23T10:03:06.292979",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2022-03-04T07:49:47.240504Z",
     "iopub.execute_input": "2022-03-04T07:49:47.240907Z",
     "iopub.status.idle": "2022-03-04T07:49:48.860296Z",
     "shell.execute_reply.started": "2022-03-04T07:49:47.240872Z",
     "shell.execute_reply": "2022-03-04T07:49:48.859536Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-17T11:05:38.647678Z",
     "start_time": "2023-11-17T11:05:38.624649700Z"
    }
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "myseed = 6696  # set a random seed for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(myseed)\n",
    "torch.manual_seed(myseed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(myseed)"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.078771,
     "end_time": "2022-02-23T10:03:08.039428",
     "exception": false,
     "start_time": "2022-02-23T10:03:07.960657",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2022-03-04T07:49:48.862365Z",
     "iopub.execute_input": "2022-03-04T07:49:48.862631Z",
     "iopub.status.idle": "2022-03-04T07:49:48.914697Z",
     "shell.execute_reply.started": "2022-03-04T07:49:48.862595Z",
     "shell.execute_reply": "2022-03-04T07:49:48.913996Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-17T11:05:38.682422300Z",
     "start_time": "2023-11-17T11:05:38.655897600Z"
    }
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Transforms\n",
    "Torchvision provides lots of useful utilities for image preprocessing, data wrapping as well as data augmentation.\n",
    "\n",
    "Please refer to PyTorch official website for details about different transforms."
   ],
   "metadata": {
    "papermill": {
     "duration": 0.01289,
     "end_time": "2022-02-23T10:03:08.065357",
     "exception": false,
     "start_time": "2022-02-23T10:03:08.052467",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Normally, We don't need augmentations in testing and validation.\n",
    "# All we need here is to resize the PIL image and transform it into Tensor.\n",
    "test_tfm = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# However, it is also possible to use augmentation in the testing phase.\n",
    "# You may use train_tfm to produce a variety of images and then test using ensemble methods\n",
    "train_tfm = transforms.Compose([\n",
    "    # Resize the image into a fixed shape (height = width = 128)\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(90),\n",
    "    # transforms.RandomGrayscale(),\n",
    "    # transforms.RandomResizedCrop,\n",
    "    # transforms.AutoAugment(),\n",
    "    # You may add some transforms here.\n",
    "    # ToTensor() should be the last one of the transforms.\n",
    "    transforms.ToTensor(),\n",
    "])\n"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.021406,
     "end_time": "2022-02-23T10:03:08.099437",
     "exception": false,
     "start_time": "2022-02-23T10:03:08.078031",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2022-03-04T07:49:48.918011Z",
     "iopub.execute_input": "2022-03-04T07:49:48.919438Z",
     "iopub.status.idle": "2022-03-04T07:49:48.924946Z",
     "shell.execute_reply.started": "2022-03-04T07:49:48.919373Z",
     "shell.execute_reply": "2022-03-04T07:49:48.924086Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-17T11:05:38.711448600Z",
     "start_time": "2023-11-17T11:05:38.686425800Z"
    }
   },
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Datasets\n",
    "The data is labelled by the name, so we load images and label while calling '__getitem__'"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.012739,
     "end_time": "2022-02-23T10:03:08.125181",
     "exception": false,
     "start_time": "2022-02-23T10:03:08.112442",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def file_to_tensor(file_name):\n",
    "    tensor_list = []  # 创建一个空的列表来存储每一行的张量\n",
    "    with open(file_name, 'r') as f:\n",
    "        lines = f.readlines()  # 读取所有行\n",
    "        for line in lines:\n",
    "            line = line.strip()  # 删除每行的空格和换行符\n",
    "            tensor = torch.tensor(float(line))  # 将字符串转换为张量\n",
    "            tensor_list.append(tensor)  # 将张量添加到列表中\n",
    "\n",
    "    return torch.stack(tensor_list)  # 使用torch.stack()将列表中的所有张量堆叠成一个新的张量\n",
    "\n",
    "file_name = \"./data/soil_data/train/train_y.txt\"\n",
    "label_train = file_to_tensor(file_name)\n",
    "file_name = \"./data/soil_data/vali/vali_y.txt\"\n",
    "label_vali = file_to_tensor(file_name)\n",
    "file_name = \"./data/soil_data/test/test_y.txt\"\n",
    "label_test = file_to_tensor(file_name)\n",
    "\n",
    "label_train_val = torch.cat((label_train, label_vali), 0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T11:05:38.723418900Z",
     "start_time": "2023-11-17T11:05:38.715452Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class FoodDataset(Dataset):\n",
    "\n",
    "    def __init__(self, label = None, tfm=test_tfm, files = None):\n",
    "        super(FoodDataset).__init__()\n",
    "        # self.path = path\n",
    "        # self.files = sorted([os.path.join(path,x) for x in os.listdir(path) if x.endswith(\".jpg\")])\n",
    "        self.files = files \n",
    "        # if files != None:\n",
    "        #     self.files = files\n",
    "        # print(f\"One sample\",self.files[0])\n",
    "        self.transform = tfm\n",
    "        self.label = label\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "  \n",
    "    def __getitem__(self,idx):\n",
    "        fname = self.files[idx]\n",
    "        im = Image.open(fname)\n",
    "        im = self.transform(im)\n",
    "        try:\n",
    "            label = self.label[idx].item()\n",
    "        except:\n",
    "            label = -1 # test has no label\n",
    "        return im,label"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.023022,
     "end_time": "2022-02-23T10:03:08.160912",
     "exception": false,
     "start_time": "2022-02-23T10:03:08.13789",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2022-03-04T07:49:48.927868Z",
     "iopub.execute_input": "2022-03-04T07:49:48.928286Z",
     "iopub.status.idle": "2022-03-04T07:49:48.93946Z",
     "shell.execute_reply.started": "2022-03-04T07:49:48.928256Z",
     "shell.execute_reply": "2022-03-04T07:49:48.938642Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2023-11-17T11:05:38.733249700Z",
     "start_time": "2023-11-17T11:05:38.723418900Z"
    }
   },
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "_dataset_dir = \"./data/soil_data/\"\n",
    "\n",
    "def dataset_prefold(path):\n",
    "    dataset = sorted([os.path.join(path,x) for x in os.listdir(path) if x.endswith(\".JPG\")])\n",
    "    return dataset\n",
    "\n",
    "train_set = dataset_prefold(os.path.join(_dataset_dir,\"train/train_x_kjg\"))\n",
    "val_set = dataset_prefold(os.path.join(_dataset_dir,\"vali/vali_x_kjg\"))\n",
    "train_val_set = train_set + val_set\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "train_val_encoded = le.fit_transform(train_val_set)\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T11:05:38.766902300Z",
     "start_time": "2023-11-17T11:05:38.734247800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# \"cuda\" only when GPUs are available.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# The number of training epochs and patience.\n",
    "n_epochs = 100\n",
    "batch_size = 64\n",
    "patience = 300 # If no improvement in 'patience' epochs, early stop"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T11:05:38.768416200Z",
     "start_time": "2023-11-17T11:05:38.747057500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n",
    "        # input 維度 [3, 128, 128]\n",
    "        # model = models.vgg16(pretr)\n",
    "        \n",
    "        self.cnn = torch.hub.load('pytorch/vision:v0.10.0','resnet50', pretrained=True)\n",
    "        \n",
    "        # self.cnn = nn.Sequential(\n",
    "        #     nn.Conv2d(3, 64, 3, 1, 1),  # [64, 128, 128]\n",
    "        #     nn.BatchNorm2d(64),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Conv2d(64, 64, 3, 1, 1),  # [64, 128, 128]\n",
    "        #     nn.BatchNorm2d(64),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.MaxPool2d(2, 2, 0),      # [64, 64, 64]\n",
    "        # \n",
    "        #     nn.Conv2d(64, 128, 3, 1, 1), # [128, 64, 64]\n",
    "        #     nn.BatchNorm2d(128),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Conv2d(128, 128, 3, 1, 1), # [128, 64, 64]\n",
    "        #     nn.BatchNorm2d(128),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.MaxPool2d(2, 2, 0),      # [128, 32, 32]\n",
    "        # \n",
    "        #     nn.Conv2d(128, 256, 3, 1, 1), # [256, 32, 32]\n",
    "        #     nn.BatchNorm2d(256),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Conv2d(256, 256, 3, 1, 1), # [256, 32, 32]\n",
    "        #     nn.BatchNorm2d(256),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Conv2d(256, 256, 3, 1, 1), # [256, 32, 32]\n",
    "        #     nn.BatchNorm2d(256),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Conv2d(256, 256, 3, 1, 1), # [256, 32, 32]\n",
    "        #     nn.BatchNorm2d(256),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.MaxPool2d(2, 2, 0),      # [256, 16, 16]\n",
    "        # \n",
    "        #     nn.Conv2d(256, 512, 3, 1, 1), # [512, 16, 16]\n",
    "        #     nn.BatchNorm2d(512),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Conv2d(512, 512, 3, 1, 1), # [512, 16, 16]\n",
    "        #     nn.BatchNorm2d(512),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Conv2d(512, 512, 3, 1, 1), # [512, 16, 16]\n",
    "        #     nn.BatchNorm2d(512),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Conv2d(512, 512, 3, 1, 1), # [512, 16, 16]\n",
    "        #     nn.BatchNorm2d(512),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.MaxPool2d(2, 2, 0),       # [512, 8, 8]\n",
    "        #     \n",
    "        #     nn.Conv2d(512, 512, 3, 1, 1), # [512, 8, 8]\n",
    "        #     nn.BatchNorm2d(512),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Conv2d(512, 512, 3, 1, 1), # [512, 8, 8]\n",
    "        #     nn.BatchNorm2d(512),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Conv2d(512, 512, 3, 1, 1), # [512, 8, 8]\n",
    "        #     nn.BatchNorm2d(512),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Conv2d(512, 512, 3, 1, 1), # [512, 8, 8]\n",
    "        #     nn.BatchNorm2d(512),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.MaxPool2d(2, 2, 0),       # [512, 4, 4]\n",
    "        # )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1000, 1000),\n",
    "            nn.ReLU(),\n",
    "            # nn.Linear(1024, 512),\n",
    "            # nn.ReLU(),\n",
    "            nn.Linear(1000, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.cnn(x)\n",
    "        out = out.view(out.size()[0], -1)\n",
    "        return self.fc(out)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T11:05:38.770416400Z",
     "start_time": "2023-11-17T11:05:38.759844300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train and Validate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "acc_scores = []\n",
    "\n",
    "with open(f\"./log/{_exp_name}_log.csv\",\"a\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"fold\", \"mode\", f\"Epoch = {n_epochs}\", \"Loss\", \"Acc\", \"Note\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T11:05:38.793181600Z",
     "start_time": "2023-11-17T11:05:38.770416400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\laish/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "C:\\Users\\laish\\miniconda3\\envs\\dpln\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\laish\\miniconda3\\envs\\dpln\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 0\n",
      "One sample of train ./data/soil_data/train/train_x_kjg\\(10).JPG\n",
      "One sample of val ./data/soil_data/train/train_x_kjg\\(1).JPG\n",
      "--------------------------------\n",
      "0, [ Train | 001/100 ] loss = 1280.99313, acc = -275.82831\n",
      "0, [ Valid | 001/100 ] loss = 1270.76135, acc = -184.98468\n",
      "0, [ Train | 002/100 ] loss = 1239.93558, acc = -258.63019\n",
      "0, [ Valid | 002/100 ] loss = 1219.80237, acc = -177.52214\n",
      "0, [ Train | 003/100 ] loss = 1185.33208, acc = -248.73695\n",
      "0, [ Valid | 003/100 ] loss = 1145.80896, acc = -166.69499\n",
      "0, [ Train | 004/100 ] loss = 1120.09410, acc = -228.17375\n",
      "0, [ Valid | 004/100 ] loss = 1078.76501, acc = -156.88086\n",
      "0, [ Train | 005/100 ] loss = 1053.91159, acc = -217.19168\n",
      "0, [ Valid | 005/100 ] loss = 1034.70276, acc = -150.43404\n",
      "0, [ Train | 006/100 ] loss = 983.53550, acc = -215.30064\n",
      "0, [ Valid | 006/100 ] loss = 992.25720, acc = -144.21661\n",
      "0, [ Train | 007/100 ] loss = 918.43970, acc = -192.23915\n",
      "0, [ Valid | 007/100 ] loss = 948.50940, acc = -137.81920\n",
      "0, [ Train | 008/100 ] loss = 850.40985, acc = -175.09543\n",
      "0, [ Valid | 008/100 ] loss = 892.72491, acc = -129.65485\n",
      "0, [ Train | 009/100 ] loss = 788.76835, acc = -159.45290\n",
      "0, [ Valid | 009/100 ] loss = 843.40674, acc = -122.43689\n",
      "0, [ Train | 010/100 ] loss = 721.59138, acc = -154.18100\n",
      "0, [ Valid | 010/100 ] loss = 791.39056, acc = -114.82405\n",
      "0, [ Train | 011/100 ] loss = 657.12515, acc = -135.53026\n",
      "0, [ Valid | 011/100 ] loss = 737.48993, acc = -106.93542\n",
      "0, [ Train | 012/100 ] loss = 592.66965, acc = -121.64155\n",
      "0, [ Valid | 012/100 ] loss = 682.95697, acc = -98.95545\n",
      "0, [ Train | 013/100 ] loss = 533.21392, acc = -119.01104\n",
      "0, [ Valid | 013/100 ] loss = 618.90308, acc = -89.57963\n",
      "0, [ Train | 014/100 ] loss = 467.22883, acc = -96.54590\n",
      "0, [ Valid | 014/100 ] loss = 553.99750, acc = -80.08037\n",
      "0, [ Train | 015/100 ] loss = 406.61157, acc = -82.55959\n",
      "0, [ Valid | 015/100 ] loss = 496.59860, acc = -71.67798\n",
      "0, [ Train | 016/100 ] loss = 357.17341, acc = -75.16402\n",
      "0, [ Valid | 016/100 ] loss = 426.28586, acc = -61.38987\n",
      "0, [ Train | 017/100 ] loss = 294.61744, acc = -60.43691\n",
      "0, [ Valid | 017/100 ] loss = 354.97644, acc = -50.95135\n",
      "0, [ Train | 018/100 ] loss = 248.49174, acc = -56.48454\n",
      "0, [ Valid | 018/100 ] loss = 285.69565, acc = -40.81302\n",
      "0, [ Train | 019/100 ] loss = 201.86016, acc = -41.15333\n",
      "0, [ Valid | 019/100 ] loss = 226.41618, acc = -32.13717\n",
      "0, [ Train | 020/100 ] loss = 152.50201, acc = -30.89079\n",
      "0, [ Valid | 020/100 ] loss = 191.71600, acc = -27.05862\n",
      "0, [ Train | 021/100 ] loss = 120.44077, acc = -24.60269\n",
      "0, [ Valid | 021/100 ] loss = 139.95573, acc = -19.48324\n",
      "0, [ Train | 022/100 ] loss = 90.04913, acc = -18.06453\n",
      "0, [ Valid | 022/100 ] loss = 112.86475, acc = -15.51893\n",
      "0, [ Train | 023/100 ] loss = 75.24002, acc = -14.59838\n",
      "0, [ Valid | 023/100 ] loss = 79.96212, acc = -10.70301\n",
      "0, [ Train | 024/100 ] loss = 50.09884, acc = -9.43490\n",
      "0, [ Valid | 024/100 ] loss = 65.92867, acc = -8.64900\n",
      "Best model found at epoch 24, saving model\n",
      "0, [ Train | 025/100 ] loss = 38.51932, acc = -6.98557\n",
      "0, [ Valid | 025/100 ] loss = 50.38620, acc = -6.37428\n",
      "Best model found at epoch 25, saving model\n",
      "0, [ Train | 026/100 ] loss = 29.50664, acc = -5.45704\n",
      "0, [ Valid | 026/100 ] loss = 40.46791, acc = -4.92261\n",
      "Best model found at epoch 26, saving model\n",
      "0, [ Train | 027/100 ] loss = 28.34176, acc = -5.02124\n",
      "0, [ Valid | 027/100 ] loss = 37.21553, acc = -4.44668\n",
      "Best model found at epoch 27, saving model\n",
      "0, [ Train | 028/100 ] loss = 25.41169, acc = -4.16480\n",
      "0, [ Valid | 028/100 ] loss = 31.35125, acc = -3.58808\n",
      "Best model found at epoch 28, saving model\n",
      "0, [ Train | 029/100 ] loss = 25.27550, acc = -4.24298\n",
      "0, [ Valid | 029/100 ] loss = 32.39364, acc = -3.74098\n",
      "0, [ Train | 030/100 ] loss = 24.88318, acc = -4.26974\n",
      "0, [ Valid | 030/100 ] loss = 26.83476, acc = -2.92745\n",
      "Best model found at epoch 30, saving model\n",
      "0, [ Train | 031/100 ] loss = 19.17715, acc = -3.09612\n",
      "0, [ Valid | 031/100 ] loss = 30.20762, acc = -3.42109\n",
      "0, [ Train | 032/100 ] loss = 21.18511, acc = -3.38085\n",
      "0, [ Valid | 032/100 ] loss = 26.66982, acc = -2.90317\n",
      "Best model found at epoch 32, saving model\n",
      "0, [ Train | 033/100 ] loss = 24.35911, acc = -4.00370\n",
      "0, [ Valid | 033/100 ] loss = 26.43158, acc = -2.86835\n",
      "Best model found at epoch 33, saving model\n",
      "0, [ Train | 034/100 ] loss = 18.28866, acc = -2.86870\n",
      "0, [ Valid | 034/100 ] loss = 25.22814, acc = -2.69222\n",
      "Best model found at epoch 34, saving model\n",
      "0, [ Train | 035/100 ] loss = 20.70295, acc = -3.25019\n",
      "0, [ Valid | 035/100 ] loss = 24.51387, acc = -2.58773\n",
      "Best model found at epoch 35, saving model\n",
      "0, [ Train | 036/100 ] loss = 21.58192, acc = -3.35431\n",
      "0, [ Valid | 036/100 ] loss = 24.84836, acc = -2.63673\n",
      "0, [ Train | 037/100 ] loss = 19.79766, acc = -3.01758\n",
      "0, [ Valid | 037/100 ] loss = 22.62914, acc = -2.31181\n",
      "Best model found at epoch 37, saving model\n",
      "0, [ Train | 038/100 ] loss = 19.92647, acc = -3.17343\n",
      "0, [ Valid | 038/100 ] loss = 23.11643, acc = -2.38329\n",
      "0, [ Train | 039/100 ] loss = 18.91258, acc = -2.92372\n",
      "0, [ Valid | 039/100 ] loss = 22.82934, acc = -2.34119\n",
      "0, [ Train | 040/100 ] loss = 16.94782, acc = -2.52408\n",
      "0, [ Valid | 040/100 ] loss = 23.50954, acc = -2.44066\n",
      "0, [ Train | 041/100 ] loss = 19.74375, acc = -3.06974\n",
      "0, [ Valid | 041/100 ] loss = 19.78660, acc = -1.89587\n",
      "Best model found at epoch 41, saving model\n",
      "0, [ Train | 042/100 ] loss = 15.03096, acc = -2.03912\n",
      "0, [ Valid | 042/100 ] loss = 20.58289, acc = -2.01245\n",
      "0, [ Train | 043/100 ] loss = 16.50846, acc = -2.49691\n",
      "0, [ Valid | 043/100 ] loss = 20.36636, acc = -1.98068\n",
      "0, [ Train | 044/100 ] loss = 15.74340, acc = -2.34355\n",
      "0, [ Valid | 044/100 ] loss = 20.70120, acc = -2.02973\n",
      "0, [ Train | 045/100 ] loss = 14.94753, acc = -2.15508\n",
      "0, [ Valid | 045/100 ] loss = 19.21755, acc = -1.81248\n",
      "Best model found at epoch 45, saving model\n",
      "0, [ Train | 046/100 ] loss = 16.22423, acc = -2.26338\n",
      "0, [ Valid | 046/100 ] loss = 17.70711, acc = -1.59153\n",
      "Best model found at epoch 46, saving model\n",
      "0, [ Train | 047/100 ] loss = 14.71245, acc = -2.09536\n",
      "0, [ Valid | 047/100 ] loss = 17.80182, acc = -1.60542\n",
      "0, [ Train | 048/100 ] loss = 13.75590, acc = -1.81460\n",
      "0, [ Valid | 048/100 ] loss = 17.92734, acc = -1.62376\n",
      "0, [ Train | 049/100 ] loss = 15.48203, acc = -2.12352\n",
      "0, [ Valid | 049/100 ] loss = 16.98681, acc = -1.48611\n",
      "Best model found at epoch 49, saving model\n",
      "0, [ Train | 050/100 ] loss = 14.69726, acc = -2.25078\n",
      "0, [ Valid | 050/100 ] loss = 17.83590, acc = -1.61031\n",
      "0, [ Train | 051/100 ] loss = 16.01582, acc = -2.41620\n",
      "0, [ Valid | 051/100 ] loss = 17.70412, acc = -1.59115\n",
      "0, [ Train | 052/100 ] loss = 12.87307, acc = -1.69575\n",
      "0, [ Valid | 052/100 ] loss = 17.18982, acc = -1.51582\n",
      "0, [ Train | 053/100 ] loss = 14.18110, acc = -1.96798\n",
      "0, [ Valid | 053/100 ] loss = 17.75089, acc = -1.59790\n",
      "0, [ Train | 054/100 ] loss = 12.56275, acc = -1.58562\n",
      "0, [ Valid | 054/100 ] loss = 17.49921, acc = -1.56113\n",
      "0, [ Train | 055/100 ] loss = 11.43841, acc = -1.38718\n",
      "0, [ Valid | 055/100 ] loss = 16.62824, acc = -1.43363\n",
      "Best model found at epoch 55, saving model\n",
      "0, [ Train | 056/100 ] loss = 13.16509, acc = -1.78455\n",
      "0, [ Valid | 056/100 ] loss = 15.69339, acc = -1.29684\n",
      "Best model found at epoch 56, saving model\n",
      "0, [ Train | 057/100 ] loss = 12.41757, acc = -1.56851\n",
      "0, [ Valid | 057/100 ] loss = 16.68585, acc = -1.44206\n",
      "0, [ Train | 058/100 ] loss = 15.07117, acc = -2.07918\n",
      "0, [ Valid | 058/100 ] loss = 16.11592, acc = -1.35868\n",
      "0, [ Train | 059/100 ] loss = 12.07441, acc = -1.50713\n",
      "0, [ Valid | 059/100 ] loss = 16.48464, acc = -1.41255\n",
      "0, [ Train | 060/100 ] loss = 11.81111, acc = -1.68646\n",
      "0, [ Valid | 060/100 ] loss = 16.02701, acc = -1.34561\n",
      "0, [ Train | 061/100 ] loss = 11.48192, acc = -1.29370\n",
      "0, [ Valid | 061/100 ] loss = 15.75542, acc = -1.30583\n",
      "0, [ Train | 062/100 ] loss = 10.92675, acc = -1.26833\n",
      "0, [ Valid | 062/100 ] loss = 15.03147, acc = -1.19993\n",
      "Best model found at epoch 62, saving model\n",
      "0, [ Train | 063/100 ] loss = 12.94787, acc = -1.58131\n",
      "0, [ Valid | 063/100 ] loss = 15.13063, acc = -1.21447\n",
      "0, [ Train | 064/100 ] loss = 11.05967, acc = -1.34669\n",
      "0, [ Valid | 064/100 ] loss = 16.41848, acc = -1.40293\n",
      "0, [ Train | 065/100 ] loss = 11.02537, acc = -1.21006\n",
      "0, [ Valid | 065/100 ] loss = 15.10264, acc = -1.21032\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[34], line 63\u001B[0m\n\u001B[0;32m     60\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m     62\u001B[0m \u001B[38;5;66;03m# Compute the gradients for parameters.\u001B[39;00m\n\u001B[1;32m---> 63\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;66;03m# Clip the gradient norms for stable training.\u001B[39;00m\n\u001B[0;32m     66\u001B[0m grad_norm \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mclip_grad_norm_(model\u001B[38;5;241m.\u001B[39mparameters(), max_norm\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\dpln\\Lib\\site-packages\\torch\\_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    486\u001B[0m     )\n\u001B[1;32m--> 487\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    489\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\dpln\\Lib\\site-packages\\torch\\autograd\\__init__.py:200\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    195\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    197\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[0;32m    198\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    199\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 200\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    201\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    202\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for fold, (train_ids, val_ids) in enumerate(kfold.split(train_val_set)):\n",
    "    # Initialize a model, and put it on the device specified.\n",
    "    model = Classifier().to(device)\n",
    "\n",
    "    # For the classification task, we use cross-entropy as the measurement of performance.\n",
    "    # criterion = nn.CrossEntropyLoss()\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Initialize optimizer, you may fine-tune some hyperparameters such as learning rate on your own.\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=0.0002, weight_decay=1e-5)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.90)\n",
    "    \n",
    "    train_images = [train_val_set[i] for i in train_ids]\n",
    "    val_images = [train_val_set[i] for i in val_ids]\n",
    "    train_label = [label_train_val[i] for i in train_ids]\n",
    "    val_label = [label_train_val[i] for i in val_ids]\n",
    "    \n",
    "    print(f'FOLD {fold}')\n",
    "    print(f\"One sample of train\",train_images[0])\n",
    "    print(f\"One sample of val\",val_images[0])\n",
    "    print('--------------------------------')\n",
    "\n",
    "    # Initialize trackers, these are not parameters and should not be changed\n",
    "    stale = 0\n",
    "    best_acc = -10\n",
    "    \n",
    "    # Construct datasets.\n",
    "    # The argument \"loader\" tells how torchvision reads the data.\n",
    "    train_set = FoodDataset(files=train_images, tfm=train_tfm, label=train_label)\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "    valid_set = FoodDataset(files=val_images, tfm=test_tfm, label=val_label)\n",
    "    valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        # ---------- Training ----------\n",
    "        # Make sure the model is in train mode before training.\n",
    "        model.train()\n",
    "\n",
    "        # These are used to record information in training.\n",
    "        train_loss = []\n",
    "        train_accs = []\n",
    "\n",
    "        for batch in train_loader:\n",
    "\n",
    "            # A batch consists of image data and corresponding labels.\n",
    "            imgs, labels = batch\n",
    "            #imgs = imgs.half()\n",
    "            #print(imgs.shape,labels.shape)\n",
    "\n",
    "            # Forward the data. (Make sure data and model are on the same device.)\n",
    "            logits = model(imgs.to(device))[:, 0]\n",
    "\n",
    "            labels = labels.to(torch.float32)\n",
    "            # Calculate the cross-entropy loss.\n",
    "            # We don't need to apply softmax before computing cross-entropy as it is done automatically.\n",
    "            loss = criterion(logits, labels.to(device))\n",
    "\n",
    "            # Gradients stored in the parameters in the previous step should be cleared out first.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Compute the gradients for parameters.\n",
    "            loss.backward()\n",
    "\n",
    "            # Clip the gradient norms for stable training.\n",
    "            grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "\n",
    "            # Update the parameters with computed gradients.\n",
    "            optimizer.step()\n",
    "\n",
    "            metric = R2Score().to(device)\n",
    "            input = logits\n",
    "            target = labels.to(device)\n",
    "            metric.update(input, target)\n",
    "            acc = metric.compute().float()\n",
    "\n",
    "            # Record the loss and accuracy.\n",
    "            train_loss.append(loss.item())\n",
    "            train_accs.append(acc)\n",
    "            \n",
    "        train_loss = sum(train_loss) / len(train_loss)\n",
    "        train_acc = sum(train_accs) / len(train_accs)\n",
    "\n",
    "        # Print the information.\n",
    "        print(f\"{fold}, [ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n",
    "        \n",
    "        # Update the log.\n",
    "        with open(f\"./log/{_exp_name}_log.csv\",\"a\", newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([fold, \"train\", f\"{epoch+1:03d}\", f\"{train_loss:.5f}\", f\"{train_acc:.5f}\", \"\"])\n",
    "\n",
    "        # ---------- Validation ----------\n",
    "        # Make sure the model is in eval mode so that some modules like dropout are disabled and work normally.\n",
    "        model.eval()\n",
    "\n",
    "        # These are used to record information in validation.\n",
    "        valid_loss = []\n",
    "        valid_accs = []\n",
    "\n",
    "        # Iterate the validation set by batches.\n",
    "        for batch in valid_loader:\n",
    "\n",
    "            # A batch consists of image data and corresponding labels.\n",
    "            imgs, labels = batch\n",
    "            #imgs = imgs.half()\n",
    "\n",
    "            # We don't need gradient in validation.\n",
    "            # Using torch.no_grad() accelerates the forward process.\n",
    "            with torch.no_grad():\n",
    "                logits = model(imgs.to(device))[:,0].to(device)\n",
    "                \n",
    "            labels = labels.to(torch.float32)\n",
    "\n",
    "            # We can still compute the loss (but not the gradient).\n",
    "            loss = criterion(logits, labels.to(device))\n",
    "\n",
    "            # Compute the accuracy for current batch.\n",
    "            metric = R2Score().to(device)\n",
    "            input = logits\n",
    "            target = labels.to(device)\n",
    "            metric.update(input, target)\n",
    "            acc = metric.compute().float()\n",
    "\n",
    "            # Record the loss and accuracy.\n",
    "            valid_loss.append(loss.item())\n",
    "            valid_accs.append(acc)\n",
    "            #break\n",
    "\n",
    "        # The average loss and accuracy for entire validation set is the average of the recorded values.\n",
    "        valid_loss = sum(valid_loss) / len(valid_loss)\n",
    "        valid_acc = sum(valid_accs) / len(valid_accs)\n",
    "\n",
    "        # Print the information.\n",
    "        print(f\"{fold}, [ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n",
    "\n",
    "        # update logs\n",
    "        with open(f\"./log/{_exp_name}_log.csv\",\"a\", newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            if valid_acc > best_acc:\n",
    "                writer.writerow([fold, \"val\", f\"{epoch+1:03d}\", f\"{valid_loss:.5f}\", f\"{valid_acc:.5f}\", \"best\"])\n",
    "            else:\n",
    "                writer.writerow([fold, \"val\", f\"{epoch+1:03d}\", f\"{valid_loss:.5f}\", f\"{valid_acc:.5f}\", \"\"])\n",
    "        \n",
    "        \n",
    "        # save models\n",
    "        if valid_acc > best_acc:\n",
    "            print(f\"Best model found at epoch {epoch + 1}, saving model\")\n",
    "            torch.save(model.state_dict(), f\"{_exp_name}_best.ckpt\") # only save best to prevent output memory exceed error\n",
    "            best_acc = valid_acc\n",
    "            stale = 0\n",
    "        else:\n",
    "            stale += 1\n",
    "            if stale > patience:\n",
    "                print(f\"No improvment {patience} consecutive epochs, early stopping\")\n",
    "                break\n",
    "                \n",
    "    acc_scores.append(best_acc)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T12:00:57.876668300Z",
     "start_time": "2023-11-17T11:05:38.782157200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testing and generate prediction CSV"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.498773,
     "end_time": "2022-02-23T19:10:20.961802",
     "exception": false,
     "start_time": "2022-02-23T19:10:20.463029",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_set = dataset_prefold(os.path.join(_dataset_dir,\"test/test_x_kjg\"))\n",
    "test_set = FoodDataset(files=test_set, tfm=test_tfm, label=label_test)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T12:00:57.882685400Z",
     "start_time": "2023-11-17T12:00:57.879184200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model_best = Classifier().to(device)\n",
    "model_best.load_state_dict(torch.load(f\"{_exp_name}_best.ckpt\"))\n",
    "model_best.eval()\n",
    "prediction = []\n",
    "with torch.no_grad():\n",
    "    for data,_ in test_loader:\n",
    "        test_pred = model_best(data.to(device))\n",
    "        test_label = test_pred.cpu().data.numpy()\n",
    "        prediction += test_label.squeeze().tolist()"
   ],
   "metadata": {
    "papermill": {
     "duration": 49.157727,
     "end_time": "2022-02-23T19:11:10.61523",
     "exception": false,
     "start_time": "2022-02-23T19:10:21.457503",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2022-03-04T07:57:48.800079Z",
     "iopub.execute_input": "2022-03-04T07:57:48.800382Z",
     "iopub.status.idle": "2022-03-04T07:58:26.536525Z",
     "shell.execute_reply.started": "2022-03-04T07:57:48.800344Z",
     "shell.execute_reply": "2022-03-04T07:58:26.535783Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2023-11-17T12:00:57.881179700Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#create test csv\n",
    "def pad4(i):\n",
    "    return \"0\"*(4-len(str(i)))+str(i)\n",
    "\n",
    "current_time = datetime.datetime.now()\n",
    "month = \"%02d\" % current_time.month\n",
    "day = \"%02d\" % current_time.day\n",
    "hour = \"%02d\" % current_time.hour\n",
    "minute = \"%02d\" % current_time.minute\n",
    "time = f\"{month}{day}{hour}{minute}\"\n",
    "# result_acc = str(round(best_acc.item(), 2))\n",
    "result_acc = str(round(0.03, 2))\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"Id\"] = [pad4(i) for i in range(1,len(test_set)+1)]\n",
    "df[\"Category\"] = prediction\n",
    "df.to_csv(\"./result/submission_\" + time + \"_\" + result_acc + \".csv\",index = False)"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.554276,
     "end_time": "2022-02-23T19:11:11.870035",
     "exception": false,
     "start_time": "2022-02-23T19:11:11.315759",
     "status": "completed"
    },
    "tags": [],
    "execution": {
     "iopub.status.busy": "2022-03-04T07:58:26.537894Z",
     "iopub.execute_input": "2022-03-04T07:58:26.53815Z",
     "iopub.status.idle": "2022-03-04T07:58:26.56908Z",
     "shell.execute_reply.started": "2022-03-04T07:58:26.538114Z",
     "shell.execute_reply": "2022-03-04T07:58:26.56829Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "start_time": "2023-11-17T12:00:57.882685400Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "os.rename(\"./log/sample_log.csv\", \"./log/samplelog_\" + time + \"_\" + result_acc + \".csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-17T12:00:57.885701500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metric = R2Score().to(device)\n",
    "metric.update(torch.tensor(prediction), label_test)\n",
    "acc = metric.compute().float()\n",
    "print(acc.item())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-17T12:00:57.886701200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-17T12:00:57.886701200Z"
    }
   }
  }
 ]
}
